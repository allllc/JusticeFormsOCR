{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR Extraction with Surya\n",
    "Extract text from document regions using Surya OCR.\n",
    "\n",
    "**Workflow:**\n",
    "1. Load layout detection results from ALL layout methods (doclayout_yolo, doctr, surya)\n",
    "2. Run OCR on each detected region\n",
    "3. Export results to JSON with layout and OCR library info\n",
    "\n",
    "**Features:**\n",
    "- Multilingual OCR support (90+ languages)\n",
    "- Modern transformer-based architecture\n",
    "- High accuracy on document text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependencies ready!\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package, \"-q\"])\n",
    "\n",
    "# Install Surya\n",
    "try:\n",
    "    import surya\n",
    "except ImportError:\n",
    "    print(\"Installing surya-ocr...\")\n",
    "    install(\"surya-ocr\")\n",
    "    import surya\n",
    "\n",
    "print(\"Dependencies ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports ready!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Image as IPImage\n",
    "\n",
    "print(\"Imports ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "INPUT_FOLDER = Path(\"filled_documents\")\n",
    "LAYOUT_RESULTS_FOLDER = Path(\"layout_results\")\n",
    "OUTPUT_FOLDER = Path(\"ocr_results\")\n",
    "OUTPUT_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# OCR Library name (for output file naming)\n",
    "OCR_LIBRARY = \"surya\"\n",
    "\n",
    "# OCR settings\n",
    "OCR_LANGS = [\"en\"]  # Languages to detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Surya OCR models...\n",
      "Surya OCR ready!\n"
     ]
    }
   ],
   "source": [
    "# Initialize Surya OCR\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "from surya.recognition import RecognitionPredictor, FoundationPredictor\n",
    "\n",
    "print(\"Loading Surya OCR models...\")\n",
    "\n",
    "# First create the foundation predictor, then the recognition predictor\n",
    "foundation_predictor = FoundationPredictor()\n",
    "recognition_predictor = RecognitionPredictor(foundation_predictor)\n",
    "\n",
    "print(\"Surya OCR ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 layout result files:\n",
      "  0: Demand Letter_batch_1_layout_doclayout_yolo.json (layout: doclayout_yolo)\n",
      "  1: Demand Letter_batch_1_layout_doctr.json (layout: doctr)\n",
      "  2: Demand Letter_batch_1_layout_surya.json (layout: surya)\n"
     ]
    }
   ],
   "source": [
    "def extract_layout_library(filename):\n",
    "    \"\"\"\n",
    "    Extract the layout library name from the JSON filename.\n",
    "    Example: 'Demand Letter_batch_1_layout_doclayout_yolo.json' -> 'doclayout_yolo'\n",
    "    \"\"\"\n",
    "    match = re.search(r'_layout_([^.]+)\\.json$', filename)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    if filename.endswith('_layout.json'):\n",
    "        return 'unknown'\n",
    "    return 'unknown'\n",
    "\n",
    "# List available layout results from ALL layout detection methods\n",
    "layout_files = sorted([f for f in LAYOUT_RESULTS_FOLDER.glob(\"*_layout_*.json\")])\n",
    "\n",
    "# Also include old format if exists\n",
    "old_format_files = sorted([f for f in LAYOUT_RESULTS_FOLDER.glob(\"*_layout.json\") \n",
    "                           if not any(f.name == lf.name for lf in layout_files)])\n",
    "layout_files.extend(old_format_files)\n",
    "\n",
    "if not layout_files:\n",
    "    print(f\"No layout JSON files found in '{LAYOUT_RESULTS_FOLDER}'.\")\n",
    "    print(\"Run the layout detection notebooks (04_*) first.\")\n",
    "else:\n",
    "    print(f\"Found {len(layout_files)} layout result files:\")\n",
    "    for i, f in enumerate(layout_files):\n",
    "        lib = extract_layout_library(f.name)\n",
    "        print(f\"  {i}: {f.name} (layout: {lib})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ocr_on_region(image, bbox):\n",
    "    \"\"\"Run Surya OCR on a specific region of the image.\"\"\"\n",
    "    x1, y1, x2, y2 = bbox['x1'], bbox['y1'], bbox['x2'], bbox['y2']\n",
    "    \n",
    "    # Crop region\n",
    "    region = image.crop((x1, y1, x2, y2))\n",
    "    \n",
    "    # For Surya, we need to provide bboxes covering the whole cropped region\n",
    "    # Since we already cropped, the bbox is the full image\n",
    "    region_w, region_h = region.size\n",
    "    full_region_bbox = [[0, 0, region_w, region_h]]  # Full region as one bbox\n",
    "    \n",
    "    # Run OCR with Surya\n",
    "    # Pass bboxes so it doesn't need DetectionPredictor\n",
    "    results = recognition_predictor(\n",
    "        [region],\n",
    "        bboxes=[full_region_bbox]\n",
    "    )\n",
    "    \n",
    "    # Extract text and confidence\n",
    "    text_lines = []\n",
    "    full_text_parts = []\n",
    "    \n",
    "    if results and len(results) > 0:\n",
    "        result = results[0]\n",
    "        \n",
    "        # Check for text_lines attribute\n",
    "        if hasattr(result, 'text_lines') and result.text_lines:\n",
    "            for line in result.text_lines:\n",
    "                text = line.text if hasattr(line, 'text') else str(line)\n",
    "                conf = line.confidence if hasattr(line, 'confidence') else 1.0\n",
    "                \n",
    "                # Get bbox if available\n",
    "                if hasattr(line, 'bbox') and line.bbox:\n",
    "                    lbbox = line.bbox\n",
    "                    bbox_dict = {\n",
    "                        \"x1\": int(lbbox[0]) if isinstance(lbbox, (list, tuple)) else 0,\n",
    "                        \"y1\": int(lbbox[1]) if isinstance(lbbox, (list, tuple)) else 0,\n",
    "                        \"x2\": int(lbbox[2]) if isinstance(lbbox, (list, tuple)) else 0,\n",
    "                        \"y2\": int(lbbox[3]) if isinstance(lbbox, (list, tuple)) else 0\n",
    "                    }\n",
    "                else:\n",
    "                    bbox_dict = {\"x1\": 0, \"y1\": 0, \"x2\": region_w, \"y2\": region_h}\n",
    "                \n",
    "                text_lines.append({\n",
    "                    \"text\": text,\n",
    "                    \"confidence\": round(float(conf), 4),\n",
    "                    \"bbox_in_region\": bbox_dict\n",
    "                })\n",
    "                full_text_parts.append(text)\n",
    "        # Check for direct text attribute\n",
    "        elif hasattr(result, 'text') and result.text:\n",
    "            text = result.text\n",
    "            conf = result.confidence if hasattr(result, 'confidence') else 1.0\n",
    "            text_lines.append({\n",
    "                \"text\": text,\n",
    "                \"confidence\": round(float(conf), 4),\n",
    "                \"bbox_in_region\": {\"x1\": 0, \"y1\": 0, \"x2\": region_w, \"y2\": region_h}\n",
    "            })\n",
    "            full_text_parts.append(text)\n",
    "    \n",
    "    full_text = \" \".join(full_text_parts)\n",
    "    \n",
    "    return {\n",
    "        \"full_text\": full_text,\n",
    "        \"lines\": text_lines\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected: Demand Letter_batch_1_layout_doclayout_yolo.json\n",
      "Layout library: doclayout_yolo\n",
      "Document: Demand Letter_batch_1.png\n",
      "Regions: 10\n",
      "Image loaded: (1224, 1584)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CONFIGURATION: Select layout file to process (for testing)\n",
    "# ============================================================\n",
    "SELECTED_LAYOUT_INDEX = 0  # Change this to select a different file\n",
    "\n",
    "if layout_files:\n",
    "    selected_layout = layout_files[SELECTED_LAYOUT_INDEX]\n",
    "    layout_library = extract_layout_library(selected_layout.name)\n",
    "    print(f\"Selected: {selected_layout.name}\")\n",
    "    print(f\"Layout library: {layout_library}\")\n",
    "    \n",
    "    # Load layout results\n",
    "    with open(selected_layout, 'r') as f:\n",
    "        layout_data = json.load(f)\n",
    "    \n",
    "    print(f\"Document: {layout_data['document']}\")\n",
    "    print(f\"Regions: {layout_data['num_regions']}\")\n",
    "    \n",
    "    # Load corresponding image\n",
    "    image_path = INPUT_FOLDER / layout_data['document']\n",
    "    if image_path.exists():\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        print(f\"Image loaded: {image.size}\")\n",
    "    else:\n",
    "        print(f\"Image not found: {image_path}\")\n",
    "else:\n",
    "    print(\"No layout files available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Surya OCR on 10 regions...\n",
      "\n",
      "Processing region 1: plain text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recognizing Text: 100%|██████████| 1/1 [00:26<00:00, 26.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Text: If you do not pay this judgment <b>immediately</b>, we will proceed to collect t...\n",
      "  Lines: 1\n",
      "\n",
      "Processing region 2: plain text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recognizing Text: 100%|██████████| 1/1 [00:27<00:00, 27.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Text: Demand is hereby made for payment of the judgment amount and, if applicable, int...\n",
      "  Lines: 1\n",
      "\n",
      "Processing region 3: plain text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recognizing Text: 100%|██████████| 1/1 [00:22<00:00, 22.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Text: If you cannot pay this judgment, <b>you have the right to designate property</b>...\n",
      "  Lines: 1\n",
      "\n",
      "Processing region 4: plain text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recognizing Text: 100%|██████████| 1/1 [00:32<00:00, 32.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Text: This notice is being sent to you as a courtesy with the intention of saving you ...\n",
      "  Lines: 1\n",
      "\n",
      "Processing region 5: title...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recognizing Text: 100%|██████████| 1/1 [00:05<00:00,  5.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Text: (Insert Constable's Letterhead)\n",
      "  Lines: 1\n",
      "\n",
      "Processing region 6: plain text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recognizing Text: 100%|██████████| 1/1 [00:07<00:00,  7.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Text: John Doe\n",
      "Defendant/Judgment Debtor\n",
      "\n",
      "123 Main St\n",
      "  Lines: 1\n",
      "\n",
      "Processing region 7: plain text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recognizing Text: 100%|██████████| 1/1 [00:03<00:00,  3.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Text: January 15 , 20 <u>26</u>\n",
      "  Lines: 1\n",
      "\n",
      "Processing region 8: plain text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recognizing Text: 100%|██████████| 1/1 [00:03<00:00,  3.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Text: Dallas, TX<br>Address\n",
      "  Lines: 1\n",
      "\n",
      "Processing region 9: title...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recognizing Text: 100%|██████████| 1/1 [00:29<00:00, 29.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Text: You are hereby notified to call (555) 111-1111 immediately to discuss the paymen...\n",
      "  Lines: 1\n",
      "\n",
      "Processing region 10: plain text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recognizing Text: 100%|██████████| 1/1 [00:29<00:00, 29.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Text: You are hereby notified to call (555) 111-1111 immediately to discuss the paymen...\n",
      "  Lines: 1\n",
      "\n",
      "OCR complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run OCR on all detected regions (single file test)\n",
    "if 'layout_data' in dir() and 'image' in dir():\n",
    "    print(f\"Running Surya OCR on {len(layout_data['regions'])} regions...\\n\")\n",
    "    \n",
    "    ocr_results = {\n",
    "        \"document\": layout_data['document'],\n",
    "        \"layout_library\": layout_library,\n",
    "        \"ocr_library\": OCR_LIBRARY,\n",
    "        \"image_width\": layout_data['image_width'],\n",
    "        \"image_height\": layout_data['image_height'],\n",
    "        \"num_regions\": len(layout_data['regions']),\n",
    "        \"regions\": []\n",
    "    }\n",
    "    \n",
    "    for region in layout_data['regions']:\n",
    "        print(f\"Processing region {region['id']}: {region['type']}...\")\n",
    "        \n",
    "        # Run OCR on this region\n",
    "        ocr_output = run_ocr_on_region(image, region['bbox'])\n",
    "        \n",
    "        # Combine layout info with OCR results\n",
    "        region_result = {\n",
    "            \"id\": region['id'],\n",
    "            \"type\": region['type'],\n",
    "            \"layout_confidence\": region['confidence'],\n",
    "            \"bbox\": region['bbox'],\n",
    "            \"ocr\": ocr_output\n",
    "        }\n",
    "        ocr_results['regions'].append(region_result)\n",
    "        \n",
    "        # Print preview\n",
    "        text_preview = ocr_output['full_text'][:80] + \"...\" if len(ocr_output['full_text']) > 80 else ocr_output['full_text']\n",
    "        print(f\"  Text: {text_preview}\")\n",
    "        print(f\"  Lines: {len(ocr_output['lines'])}\\n\")\n",
    "    \n",
    "    print(\"OCR complete!\")\n",
    "else:\n",
    "    print(\"Load layout data first (run the cells above)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "OCR RESULTS SUMMARY (Layout: doclayout_yolo, OCR: surya)\n",
      "============================================================\n",
      "\n",
      "[Region 1] plain text\n",
      "----------------------------------------\n",
      "If you do not pay this judgment <b>immediately</b>, we will proceed to collect this judgment <b>by</b> seizing any non-exempt property belonging to you according to law.\n",
      "\n",
      "\n",
      "[Region 2] plain text\n",
      "----------------------------------------\n",
      "Demand is hereby made for payment of the judgment amount and, if applicable, interest, court costs, attorney fees, and all other costs connected with collection ordered by this writ.\n",
      "\n",
      "\n",
      "[Region 3] plain text\n",
      "----------------------------------------\n",
      "If you cannot pay this judgment, <b>you have the right to designate property</b> to levy upon to satisfy this judgment if payment is not forthcoming.\n",
      "\n",
      "\n",
      "[Region 4] plain text\n",
      "----------------------------------------\n",
      "This notice is being sent to you as a courtesy with the intention of saving you time and additional costs. All payments must be made through this office to ensure proper credit toward this judgment.\n",
      "\n",
      "\n",
      "[Region 5] title\n",
      "----------------------------------------\n",
      "(Insert Constable's Letterhead)\n",
      "\n",
      "\n",
      "[Region 6] plain text\n",
      "----------------------------------------\n",
      "John Doe\n",
      "Defendant/Judgment Debtor\n",
      "\n",
      "123 Main St\n",
      "\n",
      "\n",
      "[Region 7] plain text\n",
      "----------------------------------------\n",
      "January 15 , 20 <u>26</u>\n",
      "\n",
      "\n",
      "[Region 8] plain text\n",
      "----------------------------------------\n",
      "Dallas, TX<br>Address\n",
      "\n",
      "\n",
      "[Region 9] title\n",
      "----------------------------------------\n",
      "You are hereby notified to call (555) 111-1111 immediately to discuss the payment of a judgment against you. A writ of execution has been issued on the judgment in the following case: Case #001\n",
      "\n",
      "\n",
      "[Region 10] plain text\n",
      "----------------------------------------\n",
      "You are hereby notified to call (555) 111-1111 immediately to discuss the payment of a judgment against you. A writ of execution has been issued on the judgment in the following case: Case #001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display results summary\n",
    "if 'ocr_results' in dir():\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"OCR RESULTS SUMMARY (Layout: {layout_library}, OCR: {OCR_LIBRARY})\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for region in ocr_results['regions']:\n",
    "        print(f\"\\n[Region {region['id']}] {region['type']}\")\n",
    "        print(\"-\" * 40)\n",
    "        print(region['ocr']['full_text'])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved OCR results to: ocr_results\\Demand Letter_batch_1_ocr_doclayout_yolo_surya.json\n",
      "Saved text version to: ocr_results\\Demand Letter_batch_1_ocr_doclayout_yolo_surya.txt\n"
     ]
    }
   ],
   "source": [
    "# Export results to JSON (single file)\n",
    "if 'ocr_results' in dir():\n",
    "    # Generate output filename with both layout and OCR library\n",
    "    doc_stem = Path(layout_data['document']).stem\n",
    "    json_path = OUTPUT_FOLDER / f\"{doc_stem}_ocr_{layout_library}_{OCR_LIBRARY}.json\"\n",
    "    \n",
    "    with open(json_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(ocr_results, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"Saved OCR results to: {json_path}\")\n",
    "    \n",
    "    # Also save a simple text version\n",
    "    txt_path = OUTPUT_FOLDER / f\"{doc_stem}_ocr_{layout_library}_{OCR_LIBRARY}.txt\"\n",
    "    with open(txt_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(f\"Layout: {layout_library}, OCR: {OCR_LIBRARY}\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "        for region in ocr_results['regions']:\n",
    "            f.write(f\"[{region['type']}]\\n\")\n",
    "            f.write(region['ocr']['full_text'])\n",
    "            f.write(\"\\n\\n\")\n",
    "    \n",
    "    print(f\"Saved text version to: {txt_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 3 layout files with surya...\n",
      "\n",
      "Processing: Demand Letter_batch_1_layout_doclayout_yolo.json (layout: doclayout_yolo)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recognizing Text: 100%|██████████| 1/1 [00:23<00:00, 23.96s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:27<00:00, 27.04s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:21<00:00, 21.72s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:30<00:00, 30.55s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:05<00:00,  5.35s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:07<00:00,  7.76s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:03<00:00,  3.77s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:03<00:00,  3.61s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:29<00:00, 29.33s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:29<00:00, 29.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: Demand Letter_batch_1_ocr_doclayout_yolo_surya.json\n",
      "  Regions: 10\n",
      "Processing: Demand Letter_batch_1_layout_doctr.json (layout: doctr)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.20s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.33s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.46s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.32s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.66s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.27s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.85s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.53s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.20s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.54s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.25s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.26s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.00s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.99s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.48s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.35s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.69s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.16s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.24s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.42s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.83s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.73s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.80s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.97s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.88s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.39s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.85s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.70s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.21s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.67s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.40s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.55s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.65s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.59s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.06s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.47s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.50s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.84s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.07s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.17s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.52s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.70s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.15s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.15s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.45s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.59s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.72s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.26s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.27s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.48s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.16s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.46s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.14s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.72s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.25s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.85s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.07s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.82s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.42s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.21s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.15s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.40s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.30s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.03s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.26s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.30s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.22s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.17s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.74s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.14s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.40s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.13s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.16s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.34s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.46s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.47s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.21s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.33s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.42s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.30s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.20s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.21s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.06s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.88s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.15s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.14s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.11s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.24s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.30s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.93s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.90s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.66s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.93s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.31s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.49s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.94s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.24s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.47s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.20s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.47s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.12s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.21s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.06s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.87s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.81s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.40s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.11s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.55s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.77s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.09s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.46s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.60s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.75s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.69s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.57s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.85s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.84s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.73s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.15s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.41s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.27s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.75s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.32s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.41s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.54s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.83s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.89s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.67s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.26s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.70s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.82s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.17s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.87s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.54s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.89s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.37s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.24s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.00s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.27s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.11s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.31s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.37s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.91s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.53s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.68s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.62s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.82s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.18s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.33s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.50s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.15s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:03<00:00,  3.06s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.35s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.85s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.41s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.03s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.32s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.96s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.15s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.30s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.35s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.78s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.68s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.05s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.80s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.52s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.32s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.73s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:03<00:00,  3.76s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.77s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.11s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.06s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.30s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.17s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.55s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.56s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: Demand Letter_batch_1_ocr_doctr_surya.json\n",
      "  Regions: 180\n",
      "Processing: Demand Letter_batch_1_layout_surya.json (layout: surya)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recognizing Text: 100%|██████████| 1/1 [00:05<00:00,  5.57s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:03<00:00,  3.63s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:02<00:00,  2.30s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:04<00:00,  4.57s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:03<00:00,  3.51s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:03<00:00,  3.40s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.82s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:12<00:00, 12.32s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:12<00:00, 12.95s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:04<00:00,  4.50s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:13<00:00, 13.81s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:13<00:00, 13.91s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:13<00:00, 13.30s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:10<00:00, 10.69s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:13<00:00, 13.68s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:08<00:00,  8.80s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:14<00:00, 14.41s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:14<00:00, 14.54s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:04<00:00,  4.16s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:11<00:00, 11.13s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:03<00:00,  3.62s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:04<00:00,  4.91s/it]\n",
      "Recognizing Text: 100%|██████████| 1/1 [00:04<00:00,  4.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: Demand Letter_batch_1_ocr_surya_surya.json\n",
      "  Regions: 23\n",
      "\n",
      "Done! Results saved to ocr_results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Batch process ALL layout files from ALL layout detection methods\n",
    "if layout_files:\n",
    "    print(f\"Processing {len(layout_files)} layout files with {OCR_LIBRARY}...\\n\")\n",
    "    \n",
    "    for layout_file in layout_files:\n",
    "        layout_lib = extract_layout_library(layout_file.name)\n",
    "        print(f\"Processing: {layout_file.name} (layout: {layout_lib})\")\n",
    "        \n",
    "        # Load layout\n",
    "        with open(layout_file, 'r') as f:\n",
    "            layout = json.load(f)\n",
    "        \n",
    "        # Load image\n",
    "        img_path = INPUT_FOLDER / layout['document']\n",
    "        if not img_path.exists():\n",
    "            print(f\"  Image not found: {img_path}\")\n",
    "            continue\n",
    "        \n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        # Run OCR on all regions\n",
    "        results = {\n",
    "            \"document\": layout['document'],\n",
    "            \"layout_library\": layout_lib,\n",
    "            \"ocr_library\": OCR_LIBRARY,\n",
    "            \"image_width\": layout['image_width'],\n",
    "            \"image_height\": layout['image_height'],\n",
    "            \"num_regions\": len(layout['regions']),\n",
    "            \"regions\": []\n",
    "        }\n",
    "        \n",
    "        for region in layout['regions']:\n",
    "            ocr_output = run_ocr_on_region(img, region['bbox'])\n",
    "            results['regions'].append({\n",
    "                \"id\": region['id'],\n",
    "                \"type\": region['type'],\n",
    "                \"layout_confidence\": region['confidence'],\n",
    "                \"bbox\": region['bbox'],\n",
    "                \"ocr\": ocr_output\n",
    "            })\n",
    "        \n",
    "        # Save JSON with both layout and OCR library in filename\n",
    "        doc_stem = Path(layout['document']).stem\n",
    "        json_path = OUTPUT_FOLDER / f\"{doc_stem}_ocr_{layout_lib}_{OCR_LIBRARY}.json\"\n",
    "        with open(json_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        # Save text version\n",
    "        txt_path = OUTPUT_FOLDER / f\"{doc_stem}_ocr_{layout_lib}_{OCR_LIBRARY}.txt\"\n",
    "        with open(txt_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(f\"Layout: {layout_lib}, OCR: {OCR_LIBRARY}\\n\")\n",
    "            f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "            for region in results['regions']:\n",
    "                f.write(f\"[{region['type']}]\\n\")\n",
    "                f.write(region['ocr']['full_text'])\n",
    "                f.write(\"\\n\\n\")\n",
    "        \n",
    "        print(f\"  Saved: {json_path.name}\")\n",
    "        print(f\"  Regions: {len(results['regions'])}\")\n",
    "    \n",
    "    print(f\"\\nDone! Results saved to {OUTPUT_FOLDER}\")\n",
    "else:\n",
    "    print(\"No layout files to process\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
